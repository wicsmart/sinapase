# connection settings

# connect to MongoDB using the following URL
mongo-url = "mongodb://mongo:27017"
# connect to the Elasticsearch REST API at the following node URLs
elasticsearch-urls = ["http://elasticsearch:9200"]

# frequently required settings

# if you don't want to listen for changes to all collections in MongoDB but only a few
# e.g. only listen for inserts, updates, deletes, and drops from mydb.mycollection
# this setting does not initiate a copy, it is a filter on the oplog change listener only

namespace-regex = '^enel_integrador_etl\.incidencias_calculadas$'

# additionally, if you need to seed an index from a collection and not just listen for changes from the oplog
# you can copy entire collections or views from MongoDB to Elasticsearch

direct-read-namespaces = ["enel_integrador_etl.incidencias_calculadas"]

# if you want to use MongoDB change streams instead of legacy oplog tailing add the following
# in this case you don't need regexes to filter collections.
# change streams require MongoDB version 3.6+
# change streams cannot be combined yet with resume, replay, or cluster options.
# change streams start listening for new changes since the monstache process is started

# So vale para replica set Obs: este parametro mantem o monstache escutando 
# mudancas no mongo atraves do opLog, para isso Ã© necessario setar um replSet 
# mesmo que seja de uma unica instancia
# iniciar o Dockerfile do mongo com CMD ["/usr/bin/mongod" , "--dbpath", "/data/db" ,  "--replSet" , "rs0" , "--bind_ip_all"]
# rodar rs.initiate() no mongo shell
change-stream-namespaces = ["enel_integrador_etl.incidencias_calculadas"]




[[mapping]]
namespace = "enel_integrador_etl.incidencias_calculadas"
index = "incidencia"
type = "_doc"


# additional settings

# compress requests to Elasticsearch
#gzip = true
# generate indexing statistics
#stats = true
# index statistics into Elasticsearch
#index-stats = true
# use the following PEM file for connections to MongoDB
#mongo-pem-file = "/path/to/mongoCert.pem"
# disable PEM validation
mongo-validate-pem-file = false
# use the following user name for Elasticsearch basic auth
#elasticsearch-user = "someuser"
# use the following password for Elasticsearch basic auth
#elasticsearch-password = "somepassword"
# use 4 go routines concurrently pushing documents to Elasticsearch
elasticsearch-max-conns = 4 
# use the following PEM file to connections to Elasticsearch
#elasticsearch-pem-file = "/path/to/elasticCert.pem"
# validate connections to Elasticsearch
#elastic-validate-pem-file = true
# propogate dropped collections in MongoDB as index deletes in Elasticsearch
dropped-collections = false
# propogate dropped databases in MongoDB as index deletes in Elasticsearch
dropped-databases = false
# do not start processing at the beginning of the MongoDB oplog
# if you set the replay to true you may see version conflict messages
# in the log if you had synced previously. This just means that you are replaying old docs which are already
# in Elasticsearch with a newer version. Elasticsearch is preventing the old docs from overwriting new ones.
replay = false
# resume processing from a timestamp saved in a previous run
resume = false
# do not validate that progress timestamps have been saved
resume-write-unsafe = false
# override the name under which resume state is saved
#resume-name = "default"
# exclude documents whose namespace matches the following pattern
namespace-exclude-regex = '^mydb\.ignorecollection$'
# turn on indexing of GridFS file content
index-files = false
# turn on search result highlighting of GridFS content
#file-highlighting = true
# index GridFS files inserted into the following collections
#file-namespaces = ["users.fs.files"]
# print detailed information including request traces
verbose = true
# enable clustering mode
#cluster-name = 'apollo'
# do not exit after full-sync, rather continue tailing the oplog
exit-after-direct-reads = false
